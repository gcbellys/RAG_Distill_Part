#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è°ƒè¯•Diag_Distillationç³»ç»Ÿçš„è„šæœ¬
"""

import sys
import json
import traceback
sys.path.append('/opt/RAG_Evidence4Organ')

from configs.system_config import MULTI_API_CONFIG
from Question_Distillation_v2.extractors.llm_extractor import LLMExtractor
from Diag_Distillation.prompts.medical_prompts import DiagnosticExtractionPrompts

def test_api_response():
    # è¯»å–æµ‹è¯•æ–‡ä»¶
    with open('dataset/report_10001.txt', 'r', encoding='utf-8') as f:
        test_text = f.read()
    
    # æˆªå–å‰1000å­—ç¬¦ä½œä¸ºæµ‹è¯•
    test_chunk = test_text[:1000]
    print(f"æµ‹è¯•æ–‡æœ¬é•¿åº¦: {len(test_chunk)} å­—ç¬¦")
    print(f"æµ‹è¯•æ–‡æœ¬å‰200å­—ç¬¦: {test_chunk[:200]}")
    print("-" * 60)
    
    # åˆå§‹åŒ–API
    api_config = MULTI_API_CONFIG['api_13']
    extractor = LLMExtractor(
        model=api_config['model'],
        api_key=api_config['api_key'],
        base_url=api_config['base_url']
    )
    
    # åˆå§‹åŒ–æç¤ºè¯
    prompts = DiagnosticExtractionPrompts()
    
    # æµ‹è¯•æ­¥éª¤1ï¼šæ‚£è€…ç—‡çŠ¶æå–
    print("ğŸ” æµ‹è¯•æ­¥éª¤1ï¼šæ‚£è€…ç—‡çŠ¶æå–")
    try:
        # å…ˆè·å–æç¤ºè¯æ¨¡æ¿
        prompt_template = prompts.get_step1_complaint_extraction_prompt(test_chunk)
        print(f"æç¤ºè¯æ¨¡æ¿é•¿åº¦: {len(prompt_template)} å­—ç¬¦")
        print(f"æç¤ºè¯æ¨¡æ¿æœ«å°¾200å­—ç¬¦: ...{prompt_template[-200:]}")
        
        # ç„¶åæ ¼å¼åŒ–
        prompt1 = prompt_template.format(text_content=test_chunk)
        print(f"æ ¼å¼åŒ–åæç¤ºè¯é•¿åº¦: {len(prompt1)} å­—ç¬¦")
        
        response1 = extractor.call_api(prompt1)
        print(f"APIå“åº”ç±»å‹: {type(response1)}")
        print(f"APIå“åº”: {response1}")
        
        if isinstance(response1, dict) and 'response' in response1:
            raw_text = response1['response']
            print(f"åŸå§‹å“åº”æ–‡æœ¬é•¿åº¦: {len(raw_text)}")
            print(f"åŸå§‹å“åº”å‰500å­—ç¬¦: {raw_text[:500]}")
            
            # å°è¯•è§£æJSON
            import re
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', raw_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
                print(f"æå–çš„JSONé•¿åº¦: {len(json_str)}")
                print(f"æå–çš„JSONå‰300å­—ç¬¦: {json_str[:300]}")
                try:
                    parsed = json.loads(json_str)
                    print(f"è§£ææˆåŠŸ: {type(parsed)}")
                except json.JSONDecodeError as e:
                    print(f"JSONè§£æå¤±è´¥: {e}")
            else:
                print("æœªæ‰¾åˆ°JSONæ ¼å¼ï¼Œå°è¯•ç›´æ¥è§£æ")
                try:
                    parsed = json.loads(raw_text)
                    print(f"ç›´æ¥è§£ææˆåŠŸ: {type(parsed)}")
                except json.JSONDecodeError as e:
                    print(f"ç›´æ¥è§£æå¤±è´¥: {e}")
        
    except Exception as e:
        print(f"æ­¥éª¤1æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
    
    print("=" * 60)
    
    # æµ‹è¯•æ•´åˆæç¤ºè¯
    print("ğŸ” æµ‹è¯•æ•´åˆæç¤ºè¯")
    try:
        prompt_template = prompts.get_integrated_diagnostic_prompt(test_chunk)
        print(f"æ•´åˆæç¤ºè¯æ¨¡æ¿é•¿åº¦: {len(prompt_template)} å­—ç¬¦")
        
        prompt_integrated = prompt_template.format(text_content=test_chunk)
        print(f"æ•´åˆæç¤ºè¯æ ¼å¼åŒ–åé•¿åº¦: {len(prompt_integrated)} å­—ç¬¦")
        
        response_integrated = extractor.call_api(prompt_integrated)
        print(f"æ•´åˆAPIå“åº”ç±»å‹: {type(response_integrated)}")
        print(f"æ•´åˆAPIå“åº”: {response_integrated}")
        
    except Exception as e:
        print(f"æ•´åˆæç¤ºè¯æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()

if __name__ == "__main__":
    test_api_response() 