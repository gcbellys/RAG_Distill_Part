#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
èšåˆ0805ç‰ˆæœ¬è’¸é¦ç»“æœè„šæœ¬
"""

import os
import json
import argparse
from pathlib import Path
from typing import List, Dict, Any
from loguru import logger

def aggregate_json_files(input_dir: str, output_file: str) -> None:
    """èšåˆæŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰JSONæ–‡ä»¶"""
    logger.info(f"ğŸš€ å¼€å§‹ä»ç›®å½• '{input_dir}' èšåˆç»“æœ...")
    
    if not os.path.exists(input_dir):
        logger.error(f"é”™è¯¯: è¾“å…¥ç›®å½•ä¸å­˜åœ¨ -> {input_dir}")
        return
    
    all_results = []
    worker_dirs = [d for d in os.listdir(input_dir) if d.startswith('worker_') and os.path.isdir(os.path.join(input_dir, d))]
    
    if not worker_dirs:
        logger.error(f"é”™è¯¯: åœ¨ {input_dir} ä¸­æœªæ‰¾åˆ°workerç›®å½•")
        return
    
    logger.info(f"æ‰¾åˆ° {len(worker_dirs)} ä¸ªworkerç›®å½•")
    
    for worker_dir in sorted(worker_dirs):
        worker_path = os.path.join(input_dir, worker_dir)
        logger.info(f"å¤„ç†workerç›®å½•: {worker_dir}")
        
        # æŸ¥æ‰¾è¯¥workerç›®å½•ä¸‹çš„æ‰€æœ‰JSONæ–‡ä»¶
        json_files = [f for f in os.listdir(worker_path) if f.endswith('.json')]
        
        for json_file in sorted(json_files):
            file_path = os.path.join(worker_path, json_file)
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                if isinstance(data, list):
                    all_results.extend(data)
                    logger.info(f"  {json_file}: æ·»åŠ äº† {len(data)} æ¡è®°å½•")
                else:
                    all_results.append(data)
                    logger.info(f"  {json_file}: æ·»åŠ äº† 1 æ¡è®°å½•")
                    
            except Exception as e:
                logger.error(f"è¯»å–æ–‡ä»¶ {file_path} å¤±è´¥: {e}")
    
    # ä¿å­˜èšåˆç»“æœ
    logger.info(f"ğŸ“Š æ€»å…±èšåˆäº† {len(all_results)} æ¡è®°å½•")
    
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(all_results, f, ensure_ascii=False, indent=2)
        logger.success(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
        print(f"æ€»è®°å½•æ•°: {len(all_results)}")
        
        # å™¨å®˜åˆ†å¸ƒç»Ÿè®¡
        organ_counts = {}
        organ_category_counts = {}
        
        for item in all_results:
            if isinstance(item, dict):
                organ = item.get('inferred_organ', 'Unknown')
                organ_counts[organ] = organ_counts.get(organ, 0) + 1
                
                category = item.get('organ_category', 'Unknown')
                organ_category_counts[category] = organ_category_counts.get(category, 0) + 1
        
        print(f"\nğŸ¥ å™¨å®˜åˆ†å¸ƒ (å‰10):")
        sorted_organs = sorted(organ_counts.items(), key=lambda x: x[1], reverse=True)
        for organ, count in sorted_organs[:10]:
            print(f"  {organ}: {count}")
        
        print(f"\nğŸ“‹ å™¨å®˜ç±»åˆ«åˆ†å¸ƒ:")
        for category, count in organ_category_counts.items():
            print(f"  {category}: {count}")
            
    except Exception as e:
        logger.error(f"ä¿å­˜ç»“æœæ–‡ä»¶å¤±è´¥: {e}")

def main():
    parser = argparse.ArgumentParser(description="èšåˆ0805ç‰ˆæœ¬è’¸é¦ç»“æœ")
    parser.add_argument("--input_dir", default="/hy-tmp/output_final_0805", help="è¾“å…¥ç›®å½•è·¯å¾„")
    parser.add_argument("--output_file", default="/hy-tmp/output_final_0805/final_0805_corpus.json", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    
    args = parser.parse_args()
    
    logger.info("å¼€å§‹èšåˆ0805ç‰ˆæœ¬è’¸é¦ç»“æœ...")
    aggregate_json_files(args.input_dir, args.output_file)
    logger.success("èšåˆå®Œæˆï¼")

if __name__ == "__main__":
    main() 