#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç—‡çŠ¶æå–Workerè„šæœ¬
ä¸“é—¨ç”¨äºä»åŒ»å­¦æŠ¥å‘Šä¸­æå–ç—‡çŠ¶æè¿°ï¼Œæ„å»ºæµ‹è¯•é›†
ä½œè€…: CDJ_LP
æè¿°: 
è¯¥è„šæœ¬æ˜¯ç—‡çŠ¶æå–æµç¨‹çš„æ ¸å¿ƒå·¥ä½œå•å…ƒã€‚å®ƒæ¥æ”¶ä¸€ä¸ªæ–‡ä»¶èŒƒå›´å’Œ
ä¸€ä¸ªAPIé…ç½®åç§°ï¼Œå¤„ç†æŒ‡å®šèŒƒå›´å†…çš„æŠ¥å‘Šï¼Œæå–ç—‡çŠ¶æè¿°å¹¶å°†ç»“æœä¿å­˜åˆ°ç‹¬ç«‹æ–‡ä»¶ã€‚

æ‰§è¡Œæ–¹æ³•:
python Question_set/symptom_worker.py \
    --input_dir dataset/ \
    --output_dir Question_set/results/ \
    --api_key_name api_1 \
    --start_index 40000 \
    --end_index 40100 \
    --prompt_type comprehensive
"""

import os
import sys
import json
import argparse
import re
from typing import List, Dict, Any
from loguru import logger
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = "/opt/RAG_Evidence4Organ"
sys.path.insert(0, project_root)

from Question_set.extractors.symptom_extractor import SymptomExtractor
from Question_set.prompts.symptom_prompts import SymptomExtractionPrompts, get_prompt_by_task
from Question_set.processors.document_processor import DocumentProcessor
from configs.system_config import MULTI_API_CONFIG

def numeric_sort_key(s: str):
    """ä¸ºæ•°å­—æ’åºç”Ÿæˆkey, e.g., 'report_1.txt' < 'report_2.txt' < 'report_10.txt'"""
    match = re.search(r'report_(\d+)\.txt', s)
    if match:
        return int(match.group(1))
    return 0

def load_reports_from_list(file_path: str) -> List[Dict[str, Any]]:
    """ä»æ–‡ä»¶åˆ—è¡¨æ–‡ä»¶ä¸­åŠ è½½æŠ¥å‘Š"""
    try:
        reports = []
        with open(file_path, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if not line:
                    continue
                
                if not os.path.exists(line):
                    logger.warning(f"ç¬¬{line_num}è¡Œ: æ–‡ä»¶ä¸å­˜åœ¨: {line}")
                    continue
                
                try:
                    with open(line, 'r', encoding='utf-8') as report_file:
                        content = report_file.read()
                        case_id = os.path.basename(line).replace('.txt', '')
                        reports.append({
                            "text": content,
                            "case_id": case_id,
                            "file_path": line
                        })
                except Exception as e:
                    logger.error(f"è¯»å–æŠ¥å‘Šæ–‡ä»¶ {line} å¤±è´¥: {str(e)}")
                    continue
        
        logger.info(f"ä»æ–‡ä»¶åˆ—è¡¨æˆåŠŸåŠ è½½ {len(reports)} ä¸ªæŠ¥å‘Š")
        return reports
        
    except Exception as e:
        logger.error(f"åŠ è½½æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {str(e)}")
        return []

def load_reports_in_range(input_dir: str, start_index: int, end_index: int) -> List[Dict[str, Any]]:
    """ä»æŒ‡å®šç›®å½•å’ŒèŒƒå›´åŠ è½½æŠ¥å‘Š"""
    try:
        all_files = [f for f in os.listdir(input_dir) if f.endswith('.txt') and f.startswith('report_')]
        all_files.sort(key=numeric_sort_key)
        
        if end_index > len(all_files):
            end_index = len(all_files)
            logger.warning(f"ç»“æŸç´¢å¼•è¶…å‡ºèŒƒå›´ï¼Œè°ƒæ•´ä¸º {end_index}")
        
        selected_files = all_files[start_index:end_index]
        reports = []
        
        for filename in selected_files:
            file_path = os.path.join(input_dir, filename)
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    case_id = filename.replace('.txt', '')
                    reports.append({
                        "text": content,
                        "case_id": case_id,
                        "file_path": file_path
                    })
            except Exception as e:
                logger.error(f"è¯»å–æ–‡ä»¶ {file_path} å¤±è´¥: {str(e)}")
                continue
        
        logger.info(f"ä»èŒƒå›´ [{start_index}, {end_index}) æˆåŠŸåŠ è½½ {len(reports)} ä¸ªæŠ¥å‘Š")
        return reports
        
    except Exception as e:
        logger.error(f"ä»èŒƒå›´åŠ è½½æŠ¥å‘Šå¤±è´¥: {str(e)}")
        return []

def save_symptom_results(symptoms: List[Dict[str, Any]], case_id: str, 
                        output_dirs: Dict[str, str]) -> bool:
    """ä¿å­˜ç—‡çŠ¶æå–ç»“æœåˆ°æ–‡ä»¶"""
    try:
        # ä¿å­˜JSONç»“æœ
        json_file = os.path.join(output_dirs["json"], f"{case_id}_symptoms.json")
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(symptoms, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜ç®€åŒ–çš„æ–‡æœ¬ç»“æœ
        txt_file = os.path.join(output_dirs["txt"], f"{case_id}_symptoms.txt")
        with open(txt_file, 'w', encoding='utf-8') as f:
            f.write(f"ç—…ä¾‹ID: {case_id}\n")
            f.write(f"æå–æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"ç—‡çŠ¶æ•°é‡: {len(symptoms)}\n")
            f.write("=" * 60 + "\n\n")
            
            for i, symptom in enumerate(symptoms, 1):
                f.write(f"ç—‡çŠ¶ {i}:\n")
                f.write(f"  æè¿°: {symptom.get('symptom_description', 'N/A')}\n")
                f.write(f"  ç±»å‹: {symptom.get('symptom_type', 'N/A')}\n")
                f.write(f"  èº«ä½“ç³»ç»Ÿ: {symptom.get('body_system', 'N/A')}\n")
                f.write(f"  ä¸¥é‡ç¨‹åº¦: {symptom.get('severity', 'N/A')}\n")
                f.write(f"  åŸæ–‡: {symptom.get('original_text', 'N/A')[:100]}...\n")
                f.write("-" * 40 + "\n\n")
        
        return True
        
    except Exception as e:
        logger.error(f"ä¿å­˜ç—‡çŠ¶æå–ç»“æœå¤±è´¥: {str(e)}")
        return False

def save_processing_log(case_id: str, processing_info: Dict[str, Any], 
                       output_dirs: Dict[str, str]) -> bool:
    """ä¿å­˜å¤„ç†æ—¥å¿—"""
    try:
        log_file = os.path.join(output_dirs["logs"], f"{case_id}_processing.json")
        with open(log_file, 'w', encoding='utf-8') as f:
            json.dump(processing_info, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        logger.error(f"ä¿å­˜å¤„ç†æ—¥å¿—å¤±è´¥: {str(e)}")
        return False

def process_single_report(report: Dict[str, Any], extractor: SymptomExtractor, 
                         processor: DocumentProcessor, prompt: str,
                         output_dirs: Dict[str, str]) -> Dict[str, Any]:
    """å¤„ç†å•ä¸ªæŠ¥å‘Šçš„ç—‡çŠ¶æå–"""
    
    case_id = report.get("case_id", "unknown")
    text = report.get("text", "")
    
    processing_info = {
        "case_id": case_id,
        "start_time": datetime.now().isoformat(),
        "text_length": len(text),
        "word_count": len(text.split()),
        "steps": []
    }
    
    try:
        # æ­¥éª¤1: æ–‡æ¡£é¢„å¤„ç†å’Œåˆ†å—
        processing_info["steps"].append({
            "step": "document_processing",
            "timestamp": datetime.now().isoformat(),
            "action": "å¼€å§‹æ–‡æ¡£åˆ†å—å¤„ç†"
        })
        
        chunks = processor.process_document(text, case_id)
        
        processing_info["chunks_generated"] = len(chunks)
        processing_info["steps"].append({
            "step": "document_processing",
            "timestamp": datetime.now().isoformat(),
            "action": f"æ–‡æ¡£åˆ†å—å®Œæˆï¼Œç”Ÿæˆ {len(chunks)} ä¸ªåˆ†å—"
        })
        
        if not chunks:
            logger.warning(f"ç—…ä¾‹ {case_id}: æœªç”Ÿæˆæœ‰æ•ˆåˆ†å—ï¼Œè·³è¿‡å¤„ç†")
            processing_info["status"] = "skipped"
            processing_info["reason"] = "æ— æœ‰æ•ˆåˆ†å—"
            save_processing_log(case_id, processing_info, output_dirs)
            return {"case_id": case_id, "symptoms": [], "status": "skipped"}
        
        # æ­¥éª¤2: ç—‡çŠ¶æå–
        processing_info["steps"].append({
            "step": "symptom_extraction",
            "timestamp": datetime.now().isoformat(),
            "action": "å¼€å§‹ç—‡çŠ¶æå–"
        })
        
        all_symptoms = []
        
        if len(chunks) == 1:
            # å•å—å¤„ç†
            chunk = chunks[0]
            symptoms = extractor.extract_symptoms_from_text(chunk["content"], prompt)
            all_symptoms.extend(symptoms)
        else:
            # å¤šå—å¤„ç†
            all_symptoms = extractor.extract_symptoms_from_chunks(chunks, prompt)
        
        processing_info["symptoms_extracted"] = len(all_symptoms)
        processing_info["steps"].append({
            "step": "symptom_extraction",
            "timestamp": datetime.now().isoformat(),
            "action": f"ç—‡çŠ¶æå–å®Œæˆï¼Œæå–åˆ° {len(all_symptoms)} ä¸ªç—‡çŠ¶"
        })
        
        # æ­¥éª¤3: ä¿å­˜ç»“æœ
        processing_info["steps"].append({
            "step": "save_results",
            "timestamp": datetime.now().isoformat(),
            "action": "å¼€å§‹ä¿å­˜ç»“æœ"
        })
        
        # ä¸ºæ¯ä¸ªç—‡çŠ¶æ·»åŠ é¢å¤–ä¿¡æ¯
        for symptom in all_symptoms:
            symptom["case_id"] = case_id
            symptom["extraction_timestamp"] = datetime.now().isoformat()
        
        # ä¿å­˜ç—‡çŠ¶æå–ç»“æœ
        save_success = save_symptom_results(all_symptoms, case_id, output_dirs)
        
        processing_info["end_time"] = datetime.now().isoformat()
        processing_info["status"] = "completed" if save_success else "save_failed"
        processing_info["save_success"] = save_success
        
        # ä¿å­˜å¤„ç†æ—¥å¿—
        save_processing_log(case_id, processing_info, output_dirs)
        
        logger.success(f"ç—…ä¾‹ {case_id} å¤„ç†å®Œæˆï¼šæå–åˆ° {len(all_symptoms)} ä¸ªç—‡çŠ¶")
        
        return {
            "case_id": case_id,
            "symptoms": all_symptoms,
            "status": "completed",
            "processing_info": processing_info
        }
        
    except Exception as e:
        logger.error(f"å¤„ç†ç—…ä¾‹ {case_id} æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
        processing_info["end_time"] = datetime.now().isoformat()
        processing_info["status"] = "error"
        processing_info["error"] = str(e)
        save_processing_log(case_id, processing_info, output_dirs)
        
        return {
            "case_id": case_id,
            "symptoms": [],
            "status": "error",
            "error": str(e)
        }

def main():
    parser = argparse.ArgumentParser(description="ç—‡çŠ¶æå–Workerè„šæœ¬")
    parser.add_argument("--input_dir", type=str, help="åŒ…å«åŸå§‹.txtæŠ¥å‘Šçš„ç›®å½•")
    parser.add_argument("--output_dir", type=str, required=True, help="å­˜æ”¾è¾“å‡ºç»“æœçš„ç›®å½•")
    parser.add_argument("--api_key_name", type=str, required=True, help="APIé…ç½®åç§°")
    parser.add_argument("--start_index", type=int, help="å¤„ç†çš„èµ·å§‹æ–‡ä»¶ç´¢å¼•")
    parser.add_argument("--end_index", type=int, help="å¤„ç†çš„ç»“æŸæ–‡ä»¶ç´¢å¼•")
    parser.add_argument("--file_list", type=str, help="åŒ…å«å¾…å¤„ç†æ–‡ä»¶è·¯å¾„çš„åˆ—è¡¨æ–‡ä»¶")
    parser.add_argument("--prompt_type", type=str, default="comprehensive", 
                       choices=["identification", "generation", "comprehensive", "batch"],
                       help="æç¤ºè¯ç±»å‹")
    args = parser.parse_args()

    # æ ¡éªŒå‚æ•°
    if args.file_list:
        logger.info(f"ğŸš€ ç—‡çŠ¶æå–Workerä»¥æ–‡ä»¶åˆ—è¡¨æ¨¡å¼å¯åŠ¨: API='{args.api_key_name}', ä»»åŠ¡æ–‡ä»¶='{args.file_list}'")
    elif args.input_dir and args.start_index is not None and args.end_index is not None:
        logger.info(f"ğŸš€ ç—‡çŠ¶æå–Workerä»¥èŒƒå›´æ¨¡å¼å¯åŠ¨: API='{args.api_key_name}', èŒƒå›´=[{args.start_index}, {args.end_index})")
    else:
        logger.error("å‚æ•°é”™è¯¯: å¿…é¡»æä¾› '--file_list' æˆ–è€… '--input_dir', '--start_index' å’Œ '--end_index'")
        return

    # 1. åˆå§‹åŒ–APIé…ç½®å’Œæå–å™¨
    api_config = MULTI_API_CONFIG.get(args.api_key_name)
    if not api_config:
        logger.error(f"æœªæ‰¾åˆ°APIé…ç½®: {args.api_key_name}")
        return

    extractor = SymptomExtractor(
        model=api_config["model"],
        api_key=api_config["api_key"],
        base_url=api_config["base_url"]
    )

    # 2. åˆå§‹åŒ–æ–‡æ¡£å¤„ç†å™¨
    processor = DocumentProcessor()

    # 3. è·å–æç¤ºè¯
    prompt = get_prompt_by_task(args.prompt_type)
    logger.info(f"ä½¿ç”¨æç¤ºè¯ç±»å‹: {args.prompt_type}")

    # 4. åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
    worker_output_dir = os.path.join(args.output_dir, f"worker_{args.api_key_name}")
    os.makedirs(worker_output_dir, exist_ok=True)

    output_dirs = {
        "json": os.path.join(worker_output_dir, "symptom_results"),
        "txt": os.path.join(worker_output_dir, "symptom_summaries"),
        "logs": os.path.join(worker_output_dir, "processing_logs")
    }

    for dir_path in output_dirs.values():
        os.makedirs(dir_path, exist_ok=True)

    logger.info(f"Workerè¾“å‡ºç›®å½•: {worker_output_dir}")

    # 5. åŠ è½½å¾…å¤„ç†æŠ¥å‘Š
    if args.file_list:
        reports_to_process = load_reports_from_list(args.file_list)
    else:
        reports_to_process = load_reports_in_range(args.input_dir, args.start_index, args.end_index)

    if not reports_to_process:
        logger.warning("æœªåŠ è½½åˆ°ä»»ä½•æŠ¥å‘Šï¼ŒWorkeré€€å‡º")
        return

    # 6. å¤„ç†æŠ¥å‘Š
    total_processed = 0
    total_symptoms = 0
    successful_cases = 0
    
    logger.info(f"å¼€å§‹å¤„ç† {len(reports_to_process)} ä¸ªæŠ¥å‘Š...")

    for i, report in enumerate(reports_to_process):
        try:
            logger.info(f"å¤„ç†è¿›åº¦: {i+1}/{len(reports_to_process)} - {report['case_id']}")
            
            result = process_single_report(report, extractor, processor, prompt, output_dirs)
            
            total_processed += 1
            if result["status"] == "completed":
                successful_cases += 1
                total_symptoms += len(result["symptoms"])
            
            # æ˜¾ç¤ºå¤„ç†ç»Ÿè®¡
            if (i + 1) % 10 == 0 or i == len(reports_to_process) - 1:
                logger.info(f"å¤„ç†ç»Ÿè®¡: {total_processed}/{len(reports_to_process)} å·²å¤„ç†, "
                          f"{successful_cases} æˆåŠŸ, å…±æå– {total_symptoms} ä¸ªç—‡çŠ¶")
                
        except Exception as e:
            logger.error(f"å¤„ç†æŠ¥å‘Š {i} æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
            continue

    # 7. ç”Ÿæˆæœ€ç»ˆç»Ÿè®¡æŠ¥å‘Š
    final_stats = {
        "worker_name": args.api_key_name,
        "total_reports": len(reports_to_process),
        "processed_reports": total_processed,
        "successful_reports": successful_cases,
        "total_symptoms_extracted": total_symptoms,
        "success_rate": successful_cases / total_processed if total_processed > 0 else 0,
        "avg_symptoms_per_report": total_symptoms / successful_cases if successful_cases > 0 else 0,
        "completion_time": datetime.now().isoformat(),
        "prompt_type": args.prompt_type
    }

    stats_file = os.path.join(worker_output_dir, "worker_statistics.json")
    with open(stats_file, 'w', encoding='utf-8') as f:
        json.dump(final_stats, f, ensure_ascii=False, indent=2)

    logger.success(f"ğŸ‰ Worker {args.api_key_name} å¤„ç†å®Œæˆ!")
    logger.info(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡: {successful_cases}/{total_processed} æˆåŠŸå¤„ç†, å…±æå– {total_symptoms} ä¸ªç—‡çŠ¶")
    logger.info(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {worker_output_dir}")

if __name__ == "__main__":
    main() 