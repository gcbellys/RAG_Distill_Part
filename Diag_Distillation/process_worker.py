#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Diag_Distillation Process Worker - ä¸‰æ­¥åˆ†ç¦»å¼è¯Šæ–­è’¸é¦ç³»ç»Ÿ

è¯¥è„šæœ¬å®ç°æ–°çš„ä¸‰æ­¥è¯Šæ–­è’¸é¦é€»è¾‘ï¼š
1. æ­¥éª¤1ï¼šä»æ‚£è€…é™ˆè¿°ä¸­æå–ä¸»è¯‰ç—‡çŠ¶
2. æ­¥éª¤2ï¼šä»åŒ»ç”Ÿè¯Šæ–­ä¸­æå–å™¨å®˜ä¿¡æ¯  
3. æ­¥éª¤3ï¼šå°†ç—‡çŠ¶-å™¨å®˜æ˜ å°„åˆ°å…·ä½“è§£å‰–éƒ¨ä½

ä½¿ç”¨æ–¹æ³•:
python3 process_worker.py --input_dir dataset/ --output_dir results/ --api_key_name api_13 --start_index 10001 --end_index 10001
"""

import os
import sys
import argparse
import json
import re
import time
import traceback
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any

# å¯¼å…¥é…ç½®
sys.path.append('/opt/RAG_Evidence4Organ')
from configs.system_config import MULTI_API_CONFIG
from configs.model_config import ALLOWED_ORGANS, ORGAN_ANATOMY_STRUCTURE, ELSE_STRUCT, normalize_organ
from Question_Distillation_v2.extractors.llm_extractor import LLMExtractor
from Diag_Distillation.prompts.medical_prompts import DiagnosticExtractionPrompts, get_prompt_by_step
from configs.model_config import ORGAN_ANATOMY_STRUCTURE

# å¯¼å…¥logger
try:
    from loguru import logger
except ImportError:
    # å¦‚æœæ²¡æœ‰loguruï¼Œåˆ›å»ºä¸€ä¸ªç®€å•çš„logger
    import logging
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)

def print_header():
    """æ‰“å°ç³»ç»Ÿå¯åŠ¨ä¿¡æ¯"""
    print("=" * 80)
    print("ğŸ¥ Diag_Distillation - ä¸‰æ­¥åˆ†ç¦»å¼è¯Šæ–­è’¸é¦ç³»ç»Ÿ")
    print("=" * 80)
    print(f"â° å¯åŠ¨æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ“ å·¥ä½œç›®å½•: {os.getcwd()}")
    print("ğŸ“‹ è’¸é¦æµç¨‹:")
    print("   æ­¥éª¤1: æ‚£è€…é™ˆè¿°ç—‡çŠ¶æå–")
    print("   æ­¥éª¤2: åŒ»ç”Ÿè¯Šæ–­å™¨å®˜æå–") 
    print("   æ­¥éª¤3: ç—‡çŠ¶-å™¨å®˜è§£å‰–æ˜ å°„")
    print("-" * 80)

def print_progress(current, total, start_time):
    """æ‰“å°è¿›åº¦ä¿¡æ¯"""
    elapsed = time.time() - start_time
    if current > 0:
        eta = (elapsed / current) * (total - current)
        eta_str = f"{int(eta//60)}:{int(eta%60):02d}"
    else:
        eta_str = "æœªçŸ¥"
    
    percentage = (current / total) * 100 if total > 0 else 0
    print(f"ğŸ“Š è¿›åº¦: [{current}/{total}] {percentage:.1f}% | â±ï¸ å·²ç”¨: {int(elapsed//60)}:{int(elapsed%60):02d} | ğŸ”® é¢„è®¡å‰©ä½™: {eta_str}")

def print_step_info(step_num, step_name, chunk_count=None):
    """æ‰“å°æ­¥éª¤ä¿¡æ¯"""
    step_prefix = f"ğŸ” æ­¥éª¤{step_num}"
    if chunk_count:
        print(f"{step_prefix} {step_name} (å¤„ç† {chunk_count} ä¸ªæ–‡æœ¬å—)")
    else:
        print(f"{step_prefix} {step_name}")

def print_api_call_info(api_name, report_num, step, chunk_index=None):
    """æ‰“å°APIè°ƒç”¨ä¿¡æ¯"""
    timestamp = datetime.now().strftime('%H:%M:%S')
    if chunk_index is not None:
        print(f"ğŸŒ [{timestamp}] APIè°ƒç”¨: {api_name} | æŠ¥å‘Š: {report_num} | æ­¥éª¤: {step} | å—: {chunk_index}")
    else:
        print(f"ğŸŒ [{timestamp}] APIè°ƒç”¨: {api_name} | æŠ¥å‘Š: {report_num} | æ­¥éª¤: {step}")

def print_extraction_summary(results):
    """æ‰“å°æå–ç»“æœæ‘˜è¦ï¼ˆå…¼å®¹å¤šç§ç»“æ„ï¼‰"""
    print("ğŸ“‹ æå–ç»“æœæ‘˜è¦:")

    # Handle the {"raw": ..., "normalized": ...} wrapper
    if isinstance(results, dict) and "raw" in results:
        # Prefer summarizing the normalized output if available
        if "normalized" in results and results["normalized"]:
            results = results["normalized"]
        else:
            results = results.get("raw") or {}

    # NEW: Handle the final normalized list structure: [{"s_symptom":...}]
    if isinstance(results, list) and results and "s_symptom" in results[0]:
        symptom_count = len(results)
        unit_count = sum(len(item.get("U_unit_set", [])) for item in results)
        print(f"   âœ… æ ‡å‡†åŒ–ç—‡çŠ¶æ¡ç›®: {symptom_count}")
        print(f"   âœ… æ ‡å‡†åŒ–è¯Šæ–­å•å…ƒæ€»æ•°: {unit_count}")
        if symptom_count > 0:
            first = results[0]
            s_symptom = first.get("s_symptom", "-")
            first_unit_set = first.get("U_unit_set", [])
            if first_unit_set:
                first_unit = first_unit_set[0].get("u_unit", {})
                d_diagnosis = first_unit.get("d_diagnosis", "-")
                organName = (first_unit.get("o_organ", {}) or {}).get("organName", "-")
                print(f"   ğŸ‘‰ ç¤ºä¾‹: ç—‡çŠ¶='{s_symptom}' | è¯Šæ–­='{d_diagnosis}' | å™¨å®˜='{organName}'")
            else:
                print(f"   ğŸ‘‰ ç¤ºä¾‹: ç—‡çŠ¶='{s_symptom}' | (æ— è¯Šæ–­å•å…ƒ)")
        return

    if not isinstance(results, dict):
        print(f"   âŒ ç»“æœæ ¼å¼å¼‚å¸¸: {type(results)}")
        return

    # ä¼˜å…ˆï¼šstep3 æ ·å¼
    if "symptom_organ_mappings" in results and isinstance(results["symptom_organ_mappings"], list):
        mappings = results.get("symptom_organ_mappings", [])
        count = len(mappings)
        print(f"   âœ… ç—‡çŠ¶-å™¨å®˜æ˜ å°„æ¡æ•°: {count}")
        if count > 0:
            first = mappings[0]
            ps = first.get("patient_symptom", "-")
            og = first.get("diagnosed_organ", "-")
            locs = first.get("anatomical_locations", [])
            print(f"   ğŸ‘‰ ç¤ºä¾‹: ç—‡çŠ¶='{ps}' | å™¨å®˜='{og}' | è§£å‰–éƒ¨ä½={', '.join(locs[:3])}")
        return

    # æ¬¡ä¼˜ï¼šæ•´åˆæç¤ºè¯å®Œæ•´ç»“æ„ï¼ˆstep1/2/3ï¼‰
    has_any = False
    if "step1_patient_complaints" in results:
        pcs = (results["step1_patient_complaints"] or {}).get("complaint_sections", [])
        print(f"   âœ… æ‚£è€…é™ˆè¿°æ®µè½: {len(pcs)}")
        has_any = has_any or bool(pcs)
    if "step2_physician_diagnoses" in results:
        dss = (results["step2_physician_diagnoses"] or {}).get("diagnostic_sections", [])
        print(f"   âœ… åŒ»ç”Ÿè¯Šæ–­æ®µè½: {len(dss)}")
        has_any = has_any or bool(dss)
    if "step3_anatomical_mappings" in results:
        maps = (results["step3_anatomical_mappings"] or {}).get("symptom_organ_mappings", [])
        print(f"   âœ… ç—‡çŠ¶-å™¨å®˜æ˜ å°„: {len(maps)}")
        has_any = has_any or bool(maps)
    if has_any:
        return

    # å…¼å®¹ï¼šæ—§å¼æ‰å¹³å­—æ®µï¼ˆä¸å†æ¨èï¼‰
    if results.get('patient_symptom'):
        print(f"   âœ… æ‚£è€…ç—‡çŠ¶: {results['patient_symptom'][:50]}...")
    else:
        print("   âŒ æ‚£è€…ç—‡çŠ¶: æœªæå–åˆ°")
    
    if results.get('diagnosed_organ'):
        print(f"   âœ… è¯Šæ–­å™¨å®˜: {results['diagnosed_organ']}")
    else:
        print("   âŒ è¯Šæ–­å™¨å®˜: æœªæå–åˆ°")
    
    if results.get('anatomical_locations'):
        locations = ', '.join(results['anatomical_locations'])
        print(f"   âœ… è§£å‰–éƒ¨ä½: {locations}")
    else:
        print("   âŒ è§£å‰–éƒ¨ä½: æœªæå–åˆ°")
    
    confidence = results.get('confidence', 'unknown')
    print(f"   ğŸ“ˆ ç½®ä¿¡åº¦: {confidence}")

def print_error_info(error, report_num, step=None):
    """æ‰“å°é”™è¯¯ä¿¡æ¯"""
    timestamp = datetime.now().strftime('%H:%M:%S')
    step_info = f" | æ­¥éª¤: {step}" if step else ""
    print(f"âŒ [{timestamp}] é”™è¯¯ - æŠ¥å‘Š: {report_num}{step_info}")
    print(f"   é”™è¯¯è¯¦æƒ…: {str(error)}")

def print_file_save_info(filepath, success=True):
    """æ‰“å°æ–‡ä»¶ä¿å­˜ä¿¡æ¯"""
    timestamp = datetime.now().strftime('%H:%M:%S')
    if success:
        print(f"ğŸ’¾ [{timestamp}] æ–‡ä»¶å·²ä¿å­˜: {filepath}")
    else:
        print(f"âŒ [{timestamp}] æ–‡ä»¶ä¿å­˜å¤±è´¥: {filepath}")

def numeric_sort_key(s: str):
    """ä¸ºæ•°å­—æ’åºç”Ÿæˆkey, e.g., 'report_1.txt' < 'report_2.txt' < 'report_10.txt'"""
    match = re.search(r'report_(\d+)\.txt', s)
    if match:
        return int(match.group(1))
    return 0

def load_reports_from_list(file_path: str) -> List[Dict[str, Any]]:
    """ä»ä¸€ä¸ªæ–‡ä»¶åˆ—è¡¨æ–‡ä»¶ä¸­åŠ è½½æŠ¥å‘Š"""
    print(f"æ­£åœ¨ä»ä»»åŠ¡åˆ—è¡¨ {file_path} åŠ è½½æŠ¥å‘Š...")
    reports = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            filepaths = [line.strip() for line in f if line.strip()]
        
        for report_path in filepaths:
            try:
                with open(report_path, 'r', encoding='utf-8') as report_file:
                    text = report_file.read()
                filename = os.path.basename(report_path)
                case_id_match = re.search(r'(\d+)', filename)
                case_id = case_id_match.group(1) if case_id_match else filename.replace('.txt', '')
                if text.strip():
                    reports.append({"case_id": case_id, "text": text, "filename": filename})
            except Exception as e:
                print(f"âŒ è¯»å–æŠ¥å‘Šæ–‡ä»¶ {report_path} å¤±è´¥: {e}")
        
        print(f"âœ… æˆåŠŸä»ä»»åŠ¡åˆ—è¡¨åŠ è½½ {len(reports)} æ¡æŠ¥å‘Šç”¨äºå¤„ç†ã€‚")
        return reports
    except Exception as e:
        print(f"âŒ åŠ è½½ä»»åŠ¡åˆ—è¡¨æ–‡ä»¶ {file_path} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        return []

def load_reports_in_range(directory_path: str, start_index: int, end_index: int) -> List[Dict[str, Any]]:
    """ä»ç›®å½•åŠ è½½æŒ‡å®šèŒƒå›´å†…çš„.txtæŠ¥å‘Š (ä½¿ç”¨è‡ªç„¶æ’åº)"""
    print(f"æ­£åœ¨ä»ç›®å½• {directory_path} åŠ è½½ç´¢å¼•èŒƒå›´ {start_index}-{end_index} çš„æŠ¥å‘Š...")
    reports = []
    try:
        all_files = sorted(
            [f for f in os.listdir(directory_path) if f.endswith(".txt")],
            key=numeric_sort_key
        )
        files_in_range = all_files[start_index:end_index]

        for filename in files_in_range:
            file_path = os.path.join(directory_path, filename)
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    text = f.read()
                case_id_match = re.search(r'(\d+)', filename)
                case_id = case_id_match.group(1) if case_id_match else filename.replace('.txt', '')
                if text.strip():
                    reports.append({"case_id": case_id, "text": text, "filename": filename})
            except Exception as e:
                print(f"âŒ è¯»å–æ–‡ä»¶ {filename} å¤±è´¥: {e}")
        
        print(f"âœ… æˆåŠŸåŠ è½½ {len(reports)} æ¡æŠ¥å‘Šç”¨äºå¤„ç†ã€‚")
        return reports
    except Exception as e:
        print(f"âŒ åŠ è½½ç›®å½• {directory_path} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        return []

def validate_diagnostic_extraction(extraction: Dict[str, Any]) -> bool:
    """éªŒè¯è¯Šæ–­æå–ç»“æœçš„å®Œæ•´æ€§"""
    required_fields = {
        'step1_patient_complaints': ['complaint_sections'],
        'step2_physician_diagnoses': ['diagnostic_sections'], 
        'step3_anatomical_mappings': ['symptom_organ_mappings']
    }
    
    for step, fields in required_fields.items():
        if step not in extraction:
            print(f"âš ï¸ è¯Šæ–­æå–ç¼ºå°‘æ­¥éª¤: {step}")
            return False
        for field in fields:
            if field not in extraction[step]:
                print(f"âš ï¸ æ­¥éª¤ {step} ç¼ºå°‘å­—æ®µ: {field}")
                return False
    
    return True

def parse_diagnostic_response(response_text, step_name):
    """
    è§£æLLMè¿”å›çš„è¯Šæ–­ç»“æœï¼Œå¤„ç†å„ç§å¯èƒ½çš„æ ¼å¼
    """
    if not response_text:
        print(f"   âš ï¸ {step_name}: APIè¿”å›ç©ºå“åº”")
        return None
    
    print(f"   ğŸ“„ {step_name}: æ”¶åˆ°å“åº” ({len(response_text)} å­—ç¬¦)")
    
    # å¦‚æœresponse_textæ˜¯å­—å…¸ï¼Œæå–responseå­—æ®µ
    if isinstance(response_text, dict):
        if 'response' in response_text:
            response_text = response_text['response']
            print(f"   ğŸ”§ {step_name}: ä»å­—å…¸ä¸­æå–responseå­—æ®µ")
        else:
            print(f"   âŒ {step_name}: å­—å…¸å“åº”ä¸­ç¼ºå°‘responseå­—æ®µ")
            return None
    
    # å°è¯•æå–JSON
    json_patterns = [
        r'```json\s*(\{.*?\})\s*```',  # ```json {...} ```
        r'```\s*(\{.*?\})\s*```',      # ``` {...} ```  
        r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'  # åŒ¹é…åµŒå¥—çš„JSONå¯¹è±¡
    ]
    
    for i, pattern in enumerate(json_patterns, 1):
        matches = re.findall(pattern, response_text, re.DOTALL)
        if matches:
            print(f"   ğŸ¯ {step_name}: ä½¿ç”¨æ¨¡å¼{i}æ‰¾åˆ°JSON")
            json_str = matches[0] if isinstance(matches[0], str) else matches[0]
            try:
                result = json.loads(json_str)
                print(f"   âœ… {step_name}: JSONè§£ææˆåŠŸ")
                return result
            except json.JSONDecodeError as e:
                print(f"   âš ï¸ {step_name}: JSONè§£æå¤±è´¥ (æ¨¡å¼{i}): {e}")
                continue
    
    print(f"   âŒ {step_name}: æ‰€æœ‰JSONæå–æ¨¡å¼éƒ½å¤±è´¥")
    print(f"   ğŸ“ {step_name}: åŸå§‹å“åº”å‰200å­—ç¬¦: {response_text[:200]}...")
    return None

def smart_chunk_medical_report(text: str) -> List[Dict[str, str]]:
    """
    åŸºäºåŒ»å­¦æŠ¥å‘Šç»“æ„è¿›è¡Œæ™ºèƒ½åˆ†å—ï¼Œä¸“é—¨ä¸ºè¯Šæ–­è’¸é¦ä¼˜åŒ–
    è¿”å›: [{"section": "ç« èŠ‚å", "content": "å†…å®¹", "type": "ç±»å‹"}, ...]
    """
    import re
    
    # ä¼˜åŒ–çš„ç« èŠ‚æ¨¡å¼ï¼Œåˆ†ä¸ºæ‚£è€…é™ˆè¿°å’ŒåŒ»ç”Ÿè¯Šæ–­ä¸¤ç±»
    patient_section_patterns = [
        (r'chief complaint:?', 'chief complaint'),
        (r'history of present illness:?', 'history of present illness'),
        (r'present illness:?', 'present illness'),
        (r'complaint:?', 'patient complaint'),
        (r'patient reports:?', 'patient reports'),
        (r'patient states:?', 'patient states'),
        (r'patient complains of:?', 'patient complains'),
        (r'subjective:?', 'subjective'),
        (r'symptoms:?', 'symptoms'),
        (r'clinical symptoms:?', 'clinical symptoms')
    ]
    
    physician_section_patterns = [
        (r'assessment and plan:?', 'assessment and plan'),
        (r'assessment:?', 'assessment'),
        (r'impression:?', 'impression'),
        (r'diagnosis:?', 'diagnosis'),
        (r'plan:?', 'treatment plan'),
        (r'discharge diagnosis:?', 'discharge diagnosis'),
        (r'brief hospital course:?', 'hospital course'),
        # æ–°å¢å¸¸è§è¯Šæ–­/åˆ¤æ–­ç« èŠ‚åˆ«å
        (r'final diagnosis:?', 'final diagnosis'),
        (r'clinical impression:?', 'clinical impression'),
        (r'medical decision making:?', 'medical decision making'),
        (r'\bmdm\b:?', 'medical decision making'),
        (r'findings:?', 'findings'),
        (r'ed course:?', 'ed course'),
        (r'emergency department course:?', 'ed course'),
        (r'plan and recommendations:?', 'plan and recommendations'),
        (r'disposition:?', 'disposition')
    ]
    
    chunks = []
    text_lower = text.lower()
    processed_ranges = []
    
    # å¤„ç†æ‚£è€…é™ˆè¿°ç« èŠ‚
    for pattern, canonical_name in patient_section_patterns:
        matches = list(re.finditer(pattern, text_lower))
        for match in matches:
            start_pos = match.start()
            
            # æ£€æŸ¥é‡å 
            is_overlapping = any(
                abs(start_pos - existing_start) < 300
                for existing_start, _ in processed_ranges
            )
            if is_overlapping:
                continue
            
            # æ‰¾åˆ°ç« èŠ‚ç»“æŸä½ç½®
            end_pos = len(text)
            for next_pattern, _ in patient_section_patterns + physician_section_patterns:
                next_matches = list(re.finditer(next_pattern, text_lower[start_pos + len(match.group()):]))
                if next_matches:
                    potential_end = start_pos + len(match.group()) + next_matches[0].start()
                    if potential_end > start_pos and potential_end < end_pos:
                        end_pos = potential_end
            
            section_content = text[start_pos:end_pos].strip()
            if len(section_content) > 100:  # æœ€å°é•¿åº¦è¦æ±‚
                chunks.append({
                    "section": f"patient_{canonical_name}",
                    "content": section_content,
                    "type": "patient_complaint"
                })
                processed_ranges.append((start_pos, end_pos))
                print(f"   ğŸ” è¯†åˆ«åˆ°æ‚£è€…é™ˆè¿°ç« èŠ‚: '{canonical_name}' ({len(section_content)} å­—ç¬¦)")
                break
    
    # å¤„ç†åŒ»ç”Ÿè¯Šæ–­ç« èŠ‚
    for pattern, canonical_name in physician_section_patterns:
        matches = list(re.finditer(pattern, text_lower))
        for match in matches:
            start_pos = match.start()
            
            # æ£€æŸ¥é‡å 
            is_overlapping = any(
                abs(start_pos - existing_start) < 300
                for existing_start, _ in processed_ranges
            )
            if is_overlapping:
                continue
            
            # æ‰¾åˆ°ç« èŠ‚ç»“æŸä½ç½®
            end_pos = len(text)
            for next_pattern, _ in physician_section_patterns:
                next_matches = list(re.finditer(next_pattern, text_lower[start_pos + len(match.group()):]))
                if next_matches:
                    potential_end = start_pos + len(match.group()) + next_matches[0].start()
                    if potential_end > start_pos and potential_end < end_pos:
                        end_pos = potential_end
            
            section_content = text[start_pos:end_pos].strip()
            if len(section_content) > 100:  # æœ€å°é•¿åº¦è¦æ±‚
                chunks.append({
                    "section": f"physician_{canonical_name}",
                    "content": section_content,
                    "type": "physician_diagnosis"
                })
                processed_ranges.append((start_pos, end_pos))
                print(f"   ğŸ” è¯†åˆ«åˆ°åŒ»ç”Ÿè¯Šæ–­ç« èŠ‚: '{canonical_name}' ({len(section_content)} å­—ç¬¦)")
                break
    
    if not chunks:
        print("âš ï¸ æœªæ‰¾åˆ°æ ‡å‡†ç« èŠ‚ï¼Œä½¿ç”¨æ•´ä½“å¤„ç†")
        return [{
            "section": "full_report",
            "content": text,
            "type": "mixed"
        }]
    
    print(f"   ğŸ“Š æ™ºèƒ½åˆ†å—å®Œæˆï¼Œå…± {len(chunks)} ä¸ªæœ‰æ•ˆå—")
    return chunks

def _fallback_extract_organs_on_full_text(extractor, report_text, prompts, report_num, api_key_name):
    """
    ä¸€ä¸ªå›é€€å‡½æ•°ï¼Œå½“æ™ºèƒ½åˆ†å—æœªèƒ½è¯†åˆ«åˆ°ä»»ä½•åŒ»ç”Ÿè¯Šæ–­ç« èŠ‚æ—¶ï¼Œ
    è¯¥å‡½æ•°ä¼šåœ¨æ•´ä¸ªæŠ¥å‘Šæ–‡æœ¬ä¸Šè¿è¡Œä¸€æ¬¡å™¨å®˜æå–ã€‚
    """
    results = []
    try:
        print_api_call_info(api_key_name, report_num, "å™¨å®˜æå–-æ•´ç¯‡å›é€€")
        prompt = prompts.get_step2_diagnosis_organ_extraction_prompt(report_text).replace("{text_content}", report_text)
        response = extractor.call_api(prompt)
        parsed = parse_diagnostic_response(response, "å™¨å®˜æå–-æ•´ç¯‡å›é€€")
        if parsed:
            results.append(parsed)
            print("   âœ… æ•´ç¯‡å›é€€: æˆåŠŸæå–å™¨å®˜")
        else:
            print("   âš ï¸ æ•´ç¯‡å›é€€: å™¨å®˜æå–å¤±è´¥")
    except Exception as e:
        print_error_info(e, report_num, "å™¨å®˜æå–-æ•´ç¯‡å›é€€")
    return results

def _normalize_outputs(step1_results: List[Dict[str, Any]], step2_results: List[Dict[str, Any]], mapping_result: Dict[str, Any], original_text: str) -> List[Dict[str, Any]]:
    """
    å°†ä¸‰æ­¥ç»“æœè§„èŒƒåŒ–ä¸ºæ‰€éœ€ç»“æ„ï¼š
    æŒ‰ç…§æ–°çš„JSONç»“æ„è¾“å‡ºï¼šs_symptom -> U_unit_set -> u_unit -> (d_diagnosis, o_organ, b_textual_basis)
    
    ä¸¥æ ¼çº¦æŸï¼š
    1. åªä½¿ç”¨é¢„å®šä¹‰çš„å™¨å®˜åˆ—è¡¨
    2. å¿…é¡»æœ‰å…·ä½“çš„è§£å‰–ä½ç½®ï¼ˆä¸èƒ½æ˜¯"General area"ç­‰ï¼‰
    3. æ— æ³•ç¡®å®šå™¨å®˜çš„ç—‡çŠ¶ç›´æ¥è¿‡æ»¤æ‰
    """
    # _organ_key_matchå‡½æ•°å·²åˆ é™¤ï¼Œç°åœ¨ä½¿ç”¨configs/model_config.pyä¸­çš„normalize_organå‡½æ•°
    
    def _is_body_system_match(body_system: str, organ_name: str) -> bool:
        """æ£€æŸ¥èº«ä½“ç³»ç»Ÿæ˜¯å¦ä¸å™¨å®˜åŒ¹é…"""
        system_organ_map = {
            "cardiovascular": ["Heart (Cor)", "Artery (Arteria)", "Vein (Vena)"],
            "respiratory": ["Lung (Pulmo)", "Trachea", "Bronchus"],
            "gastrointestinal": ["Liver (Hepar)", "Stomach (Gaster)", "Pancreas", "Esophagus"],
            "neurological": ["Brain", "Cerebellum", "Brainstem"],
            "genitourinary": ["Kidney (Ren)", "Urinary bladder (Vesica urinaria)"],
            "endocrine": ["Thyroid gland", "Pancreas", "Adrenal gland (Suprarenal gland)"]
        }
        
        for organ in system_organ_map.get(body_system, []):
            if organ.lower() in organ_name.lower() or organ_name.lower() in organ.lower():
                return True
        return False
    
    def _get_default_anatomical_locations(organ_name: str) -> list:
        """ä¸ºå™¨å®˜è·å–é»˜è®¤çš„è§£å‰–ä½ç½®"""
        normalized_organ = normalize_organ(organ_name)
        if normalized_organ in ORGAN_ANATOMY_STRUCTURE:
            return ORGAN_ANATOMY_STRUCTURE[normalized_organ][:2]  # è¿”å›å‰2ä¸ªä½ç½®
        return ["General area", "Main structure"]

    # ï¼ˆæœ¬æ®µä¿ç•™ç©ºè¡Œç”¨äºå¯è¯»æ€§ï¼‰

    # ---------------------- ä»¥ä¸Šï¼šæ–°å¢å·¥å…·å‡½æ•° ----------------------

    # --- ä½¿ç”¨model_config.pyä¸­çš„å®Œæ•´å™¨å®˜åˆ—è¡¨ ---
    # ALLOWED_ORGANS ç°åœ¨ä» configs/model_config.py å¯¼å…¥ï¼ŒåŒ…å«55ä¸ªå™¨å®˜
    print(f"   ğŸ”§ ä½¿ç”¨å®Œæ•´å™¨å®˜åˆ—è¡¨: {len(ALLOWED_ORGANS)} ä¸ªå™¨å®˜")
    
    # å™¨å®˜åç§°æ ‡å‡†åŒ–å‡½æ•°ç°åœ¨ä» model_config.py å¯¼å…¥

    print("   ğŸ”„ å¼€å§‹æ ‡å‡†åŒ–æ–°çš„æè¿°æ€§å†…å®¹ç»“æ„...")
    
    # æ”¶é›†æ‰€æœ‰æè¿°æ€§å‘ç° (s_symptom) - é€‚é…æ–°çš„æ•°æ®ç»“æ„
    all_descriptive_findings = []
    
    # ä»step1ç»“æœä¸­æå–æè¿°æ€§å‘ç°
    for obj in (step1_results or []):
        try:
            # æ–°ç»“æ„ï¼šä»descriptive_findingsä¸­æå–
            findings = obj.get("descriptive_findings", [])
            for finding in findings:
                if finding and isinstance(finding, dict):
                    finding_text = finding.get("finding_text", "")
                    if finding_text:
                        all_descriptive_findings.append({
                            "s_symptom": finding_text,
                            "finding_type": finding.get("finding_type", "unknown"),
                            "source_quote": finding.get("source_quote", ""),
                            "body_system": finding.get("body_system", "other"),
                            "confidence": finding.get("extraction_confidence", "medium")
                        })
            
            # å…¼å®¹æ—§ç»“æ„ï¼šä»symptom_sectionsä¸­æå–
            sections = obj.get("symptom_sections", []) or obj.get("patient_complaint_sections", [])
            for sec in sections:
                symptoms = sec.get("extracted_symptoms", []) or sec.get("main_symptoms", [])
                for symptom in symptoms:
                    if symptom and isinstance(symptom, str):
                        all_descriptive_findings.append({
                            "s_symptom": symptom,
                            "finding_type": "patient_symptom",
                            "source_quote": sec.get("original_text", ""),
                            "body_system": "other",
                            "confidence": "medium"
                        })
            
            print(f"   ğŸ“Š ä»step1æå–åˆ° {len(findings)} ä¸ªæè¿°æ€§å‘ç°")
        except Exception as e:
            print(f"   âš ï¸ æè¿°æ€§å‘ç°è§£æé”™è¯¯: {e}")
            continue
    
    # æ”¶é›†æ‰€æœ‰åŒ»ç”Ÿè¯Šæ–­
    all_diagnoses = []
    
    # ä»step2ç»“æœä¸­æå–è¯Šæ–­
    for obj in (step2_results or []):
        try:
            # æ–°ç»“æ„ï¼šä»physician_diagnosesä¸­æå–
            diagnoses = obj.get("physician_diagnoses", [])
            for diagnosis in diagnoses:
                if diagnosis and isinstance(diagnosis, dict):
                    diagnosis_text = diagnosis.get("diagnosis_text", "")
                    affected_organs = diagnosis.get("affected_organs", [])
                    if diagnosis_text and affected_organs:
                        all_diagnoses.append({
                            "diagnosis": diagnosis_text,
                            "organs": affected_organs,
                            "source_quote": diagnosis.get("source_quote", ""),
                            "confidence": diagnosis.get("extraction_confidence", "medium")
                        })
            
            # å…¼å®¹æ—§ç»“æ„ï¼šä»diagnostic_sectionsä¸­æå–
            sections = obj.get("diagnostic_sections", [])
            for sec in sections:
                mentioned_organs = sec.get("mentioned_organs", [])
                for organ_info in mentioned_organs:
                    if isinstance(organ_info, dict):
                        organ_name = organ_info.get("organ_name", "")
                        context = organ_info.get("context", "")
                        if organ_name and context:
                            all_diagnoses.append({
                                "diagnosis": context,
                                "organs": [{"organ_name": organ_name, "organ_confidence": "medium", "organ_basis": context}],
                                "source_quote": sec.get("original_text", ""),
                                "confidence": "medium"
                            })
            
            print(f"   ğŸ“Š ä»step2æå–åˆ° {len(diagnoses)} ä¸ªåŒ»ç”Ÿè¯Šæ–­")
        except Exception as e:
            print(f"   âš ï¸ è¯Šæ–­è§£æé”™è¯¯: {e}")
            continue

    # è·å–ç—‡çŠ¶-å™¨å®˜æ˜ å°„
    mapping_list = (mapping_result or {}).get("symptom_organ_mappings", []) if isinstance(mapping_result, dict) else []
    print(f"   ğŸ“Š è·å–åˆ° {len(mapping_list)} ä¸ªç—‡çŠ¶-å™¨å®˜æ˜ å°„")

    # æ„å»ºæœ€ç»ˆæ ‡å‡†åŒ–è¾“å‡ºç»“æ„: s â†’ U
    final_output = []
    
    # ğŸ”§ ä¿®å¤ï¼šä»æ˜ å°„ä¸­æå–æ‰€æœ‰å”¯ä¸€ç—‡çŠ¶ï¼Œè€Œä¸ä»…ä»…ä¾èµ–Step1
    all_unique_symptoms = set()
    
    # ä»æè¿°æ€§å‘ç°ä¸­æ”¶é›†ç—‡çŠ¶
    for finding in all_descriptive_findings:
        all_unique_symptoms.add(finding["s_symptom"])
    
    # ä»æ˜ å°„ä¸­æ”¶é›†é¢å¤–çš„ç—‡çŠ¶ï¼ˆé˜²æ­¢Step1é—æ¼ï¼‰
    for mp in mapping_list:
        if isinstance(mp, dict) and mp.get("patient_symptom"):
            all_unique_symptoms.add(mp.get("patient_symptom"))
    
    print(f"   ğŸ“Š å‘ç° {len(all_unique_symptoms)} ä¸ªå”¯ä¸€ç—‡çŠ¶éœ€è¦å¤„ç†")
    
    for s_symptom in all_unique_symptoms:
        print(f"   ğŸ” å¤„ç†ç—‡çŠ¶: {s_symptom}")
        
        # ä¸ºæ¯ä¸ªç—‡çŠ¶æ„å»ºU_unit_set
        U_unit_set = []
        
        # æ‰¾åˆ°ä¸è¯¥ç—‡çŠ¶ç›¸å…³çš„æ‰€æœ‰æ˜ å°„
        symptom_mappings = []
        for mp in mapping_list:
            if isinstance(mp, dict) and mp.get("patient_symptom") == s_symptom:
                symptom_mappings.append(mp)
        
        # å¦‚æœæ²¡æœ‰ç›´æ¥æ˜ å°„ï¼Œå°è¯•é€šè¿‡è¯Šæ–­ä¿¡æ¯åˆ›å»ºæ˜ å°„
        if not symptom_mappings:
            # æŸ¥æ‰¾å¯¹åº”çš„æè¿°æ€§å‘ç°ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            finding_info = None
            for finding in all_descriptive_findings:
                if finding["s_symptom"] == s_symptom:
                    finding_info = finding
                    break
            
            # æ ¹æ®æè¿°æ€§å‘ç°çš„body_systemå°è¯•åŒ¹é…ç›¸å…³è¯Šæ–­
            finding_body_system = finding_info.get("body_system", "other") if finding_info else "other"
            
            for diagnosis in all_diagnoses:
                for organ_info in diagnosis.get("organs", []):
                    organ_name = organ_info.get("organ_name", "")
                    if organ_name and _is_body_system_match(finding_body_system, organ_name):
                        # åˆ›å»ºæ˜ å°„
                        synthetic_mapping = {
                            "patient_symptom": s_symptom,
                            "diagnosed_organ": organ_name,
                            "anatomical_locations": _get_default_anatomical_locations(organ_name),
                            "text_evidence": {
                                "symptom_source": finding_info.get("source_quote", "") if finding_info else "",
                                "diagnosis_source": diagnosis.get("source_quote", ""),
                                "anatomical_basis": f"Based on {finding_body_system} system involvement and diagnosis context."
                            }
                        }
                        symptom_mappings.append(synthetic_mapping)
                        print(f"   ğŸ”— åˆ›å»ºåˆæˆæ˜ å°„: {s_symptom} -> {organ_name}")
                        break
        
        # å¤„ç†æ‰¾åˆ°çš„æ˜ å°„
        for mp in symptom_mappings:
            organ_name_raw = mp.get("diagnosed_organ", "")
            normalized_organ = normalize_organ(organ_name_raw)
            locations = mp.get("anatomical_locations", []) or []
            
            # å™¨å®˜éªŒè¯ï¼šä½¿ç”¨normalize_organå‡½æ•°å’Œå®Œæ•´çš„ALLOWED_ORGANSåˆ—è¡¨
            if normalized_organ == "unknown" or normalized_organ not in ALLOWED_ORGANS:
                print(f"   ğŸ—‘ï¸ è¿‡æ»¤æ‰éé¢„å®šä¹‰å™¨å®˜: {organ_name_raw} -> {normalized_organ}")
                continue
            
            # ä¸¥æ ¼è§£å‰–ä½ç½®éªŒè¯ï¼šå¿…é¡»æœ‰å…·ä½“ä½ç½®ï¼Œä¸èƒ½æ˜¯æ¨¡ç³Šæè¿°
            if not locations:
                print(f"   ğŸ—‘ï¸ è¿‡æ»¤æ‰æ— è§£å‰–ä½ç½®çš„ç—‡çŠ¶: {s_symptom}")
                continue
            
            # è¿‡æ»¤æ‰æ¨¡ç³Šçš„è§£å‰–ä½ç½®æè¿°
            vague_locations = ["general area", "multiple systems", "general", "unspecified", "unknown"]
            filtered_locations = []
            for loc in locations:
                loc_lower = loc.lower()
                if not any(vague in loc_lower for vague in vague_locations):
                    filtered_locations.append(loc)
            
            # å¦‚æœè¿‡æ»¤åæ²¡æœ‰å…·ä½“ä½ç½®ï¼Œè·³è¿‡è¿™ä¸ªç—‡çŠ¶
            if not filtered_locations:
                print(f"   ğŸ—‘ï¸ è¿‡æ»¤æ‰åªæœ‰æ¨¡ç³Šè§£å‰–ä½ç½®çš„ç—‡çŠ¶: {s_symptom} -> {normalized_organ}")
                continue
            
            # ç¡®ä¿è‡³å°‘æœ‰2ä¸ªå…·ä½“çš„è§£å‰–ä½ç½®
            if len(filtered_locations) < 2:
                # ä»é¢„å®šä¹‰ç»“æ„ä¸­è¡¥å……å…·ä½“ä½ç½®
                if normalized_organ in ORGAN_ANATOMY_STRUCTURE:
                    available = [loc for loc in ORGAN_ANATOMY_STRUCTURE[normalized_organ] 
                               if loc not in filtered_locations and 
                               not any(vague in loc.lower() for vague in vague_locations)]
                    while len(filtered_locations) < 2 and available:
                        filtered_locations.append(available.pop(0))
                
                # å¦‚æœä»ç„¶å°‘äº2ä¸ªï¼Œè·³è¿‡è¿™ä¸ªç—‡çŠ¶
                if len(filtered_locations) < 2:
                    print(f"   ğŸ—‘ï¸ è¿‡æ»¤æ‰è§£å‰–ä½ç½®ä¸è¶³çš„ç—‡çŠ¶: {s_symptom} -> {normalized_organ} (åªæœ‰{len(filtered_locations)}ä¸ªä½ç½®)")
                    continue
            
            # æ„å»ºu_unit
            text_evidence = mp.get("text_evidence", {}) or {}
            
            # éªŒè¯è¯Šæ–­ä¿¡æ¯ - é€‚é…æ–°ç»“æ„
            diagnosis = text_evidence.get("diagnosis_source", "") or text_evidence.get("organ_source", "")
            if not diagnosis or diagnosis.lower() in ["unknown", "unknown diagnosis", "n/a"]:
                print(f"   ğŸ—‘ï¸ è¿‡æ»¤æ‰è¯Šæ–­ä¿¡æ¯ä¸æ˜çš„ç—‡çŠ¶: {s_symptom}")
                continue
            
            u_unit = {
                "d_diagnosis": diagnosis,
                "o_organ": {
                    "organName": normalized_organ,
                    "anatomicalLocations": filtered_locations[:3]  # æœ€å¤š3ä¸ªä½ç½®
                },
                "b_textual_basis": {
                    "doctorsDiagnosisAndJudgment": diagnosis,
                    "medicalInference": text_evidence.get("anatomical_basis", f"Clinical evidence indicates {normalized_organ} involvement with specific anatomical locations: {', '.join(filtered_locations)}.")
                }
            }
            U_unit_set.append({"u_unit": u_unit})
            print(f"   âœ… æˆåŠŸåˆ›å»ºè¯Šæ–­å•å…ƒ: {s_symptom} -> {normalized_organ} -> {filtered_locations}")
        
        # å…³é”®çº¦æŸï¼šå¦‚æœU_unit_setä¸ºç©ºï¼Œç›´æ¥è·³è¿‡è¿™ä¸ªæè¿°æ€§å‘ç°ï¼Œä¸è®°å½•åœ¨JSONä¸­
        if not U_unit_set:
            print(f"   ğŸ—‘ï¸ æè¿°æ€§å‘ç° '{s_symptom}' æ— æ³•ç¡®å®šå™¨å®˜æˆ–è§£å‰–ä½ç½®ï¼Œå·²è¿‡æ»¤æ‰")
            continue
        
        # æ„å»ºæœ€ç»ˆçš„s_symptomæ¡ç›® - æ ‡å‡†åŒ–æ ¼å¼ s â†’ Uï¼ˆæ¢å¤æ— æ¡ä»¶åŠ å…¥ï¼‰
        final_output.append({
            "s_symptom": s_symptom,
            "U_unit_set": U_unit_set
        })
    
    print(f"   ğŸ“Š æœ€ç»ˆè¾“å‡º: {len(final_output)} ä¸ªæœ‰æ•ˆç—‡çŠ¶ï¼ˆå·²è¿‡æ»¤æ‰æ— æ³•ç¡®å®šå™¨å®˜çš„ç—‡çŠ¶ï¼‰")
    return final_output

def process_report_with_diagnostic_steps(extractor, report_data, report_num, prompts, api_key_name):
    """
    ä½¿ç”¨ä¸‰æ­¥è¯Šæ–­æ³•å¤„ç†å•ä¸ªæŠ¥å‘Š
    """
    print(f"\nğŸ¥ å¼€å§‹å¤„ç†æŠ¥å‘Š {report_num}")
    print("-" * 60)
    
    # è·å–æŠ¥å‘Šæ–‡æœ¬ (å…¼å®¹txtå’Œjsonæ ¼å¼)
    report_text = report_data.get('text', '') or report_data.get('medical_record_content', '')
    if not report_text:
        print(f"âŒ æŠ¥å‘Š {report_num}: ç¼ºå°‘åŒ»ç–—è®°å½•å†…å®¹")
        return None
    
    print(f"ğŸ“„ æŠ¥å‘Šå†…å®¹é•¿åº¦: {len(report_text)} å­—ç¬¦")
    
    # ç¬¬ä¸€æ­¥ï¼šæ™ºèƒ½åˆ†å—å’Œåˆ†ç±»
    print_step_info(1, "æ™ºèƒ½åˆ†å—å’Œç—‡çŠ¶æå–")
    chunks = smart_chunk_medical_report(report_text)
    patient_chunks = [chunk for chunk in chunks if chunk.get('type') == 'patient_complaint']
    physician_chunks = [chunk for chunk in chunks if chunk.get('type') == 'physician_diagnosis']
    
    print(f"   ğŸ“Š æ€»å—æ•°: {len(chunks)} | æ‚£è€…é™ˆè¿°å—: {len(patient_chunks)} | åŒ»ç”Ÿè¯Šæ–­å—: {len(physician_chunks)}")
    
    # ç¬¬äºŒæ­¥ï¼šä»æ‚£è€…é™ˆè¿°å’Œå…¶ä»–ç« èŠ‚ä¸­æå–æè¿°æ€§å†…å®¹ï¼ˆç—‡çŠ¶ã€æ£€æŸ¥ã€ä½“å¾ï¼‰
    print_step_info(2, "ç»¼åˆæè¿°æ€§å†…å®¹æå–", len(patient_chunks))
    patient_symptoms = []
    
    # ä¼˜å…ˆå¤„ç†æ‚£è€…é™ˆè¿°å— - æå–æè¿°æ€§å†…å®¹
    for i, chunk in enumerate(patient_chunks):
        print_api_call_info(api_key_name, report_num, "æè¿°æ€§å†…å®¹æå–", i+1)
        try:
            prompt = prompts.get_step1_comprehensive_descriptive_extraction_prompt(chunk['content'])
            response = extractor.call_api(prompt)
            parsed = parse_diagnostic_response(response, f"æè¿°æ€§å†…å®¹æå–-å—{i+1}")
            if parsed and parsed.get("descriptive_findings"):
                patient_symptoms.append(parsed)
                findings_count = len(parsed.get('descriptive_findings', []))
                excluded_count = len(parsed.get('excluded_content', []))
                print(f"   âœ… å—{i+1}: æå–{findings_count}ä¸ªæè¿°æ€§å‘ç°ï¼Œæ’é™¤{excluded_count}ä¸ªè¯Šæ–­åˆ¤æ–­")
            else:
                print(f"   âš ï¸ å—{i+1}: æœªå‘ç°æœ‰æ•ˆæè¿°æ€§å†…å®¹")
        except Exception as e:
            print_error_info(e, report_num, f"æè¿°æ€§å†…å®¹æå–-å—{i+1}")
    
    # å¦‚æœæ‚£è€…é™ˆè¿°å—ä¸­æ²¡æœ‰æå–åˆ°è¶³å¤Ÿç—‡çŠ¶ï¼Œå°è¯•ä»å…¶ä»–ç« èŠ‚æå–
    if not patient_symptoms or len(patient_symptoms) < 2:
        print("   ğŸ” æ‚£è€…é™ˆè¿°å—ç—‡çŠ¶ä¸è¶³ï¼Œå°è¯•ä»åŒ»ç”Ÿè¯Šæ–­çš„å™äº‹ç« èŠ‚æå–ç—‡çŠ¶")
        
        # æ™ºèƒ½é€‰æ‹©å¯èƒ½åŒ…å«ç—‡çŠ¶çš„åŒ»ç”Ÿè¯Šæ–­å—ï¼ˆåå‘å™äº‹æ€§ï¼‰
        narrative_physician_chunks = [
            chunk for chunk in physician_chunks 
            if any(keyword in chunk['section'] for keyword in ['course', 'history', 'narrative'])
        ]

        # ä»ç­›é€‰å‡ºçš„åŒ»ç”Ÿè¯Šæ–­å—ä¸­å¯»æ‰¾æè¿°æ€§å†…å®¹
        for i, chunk in enumerate(narrative_physician_chunks):
            print_api_call_info(api_key_name, report_num, f"æè¿°æ€§å†…å®¹æå–-åŒ»ç”Ÿå™äº‹å—{i+1}")
            try:
                prompt = prompts.get_step1_comprehensive_descriptive_extraction_prompt(chunk['content'])
                response = extractor.call_api(prompt)
                parsed = parse_diagnostic_response(response, f"æè¿°æ€§å†…å®¹æå–-åŒ»ç”Ÿå™äº‹å—{i+1}")
                if parsed and parsed.get("descriptive_findings"):
                    patient_symptoms.append(parsed)
                    findings_count = len(parsed.get('descriptive_findings', []))
                    print(f"   âœ… åŒ»ç”Ÿå™äº‹å—{i+1}: æå–{findings_count}ä¸ªæè¿°æ€§å‘ç°")
            except Exception as e:
                print_error_info(e, report_num, f"æè¿°æ€§å†…å®¹æå–-åŒ»ç”Ÿå™äº‹å—{i+1}")
    
    # å¦‚æœä»ç„¶æ²¡æœ‰æè¿°æ€§å†…å®¹ï¼Œå°è¯•ä»æ•´ç¯‡æ–‡æœ¬æå–
    if not patient_symptoms:
        print("   ğŸ” åˆ†å—æè¿°æ€§å†…å®¹æå–å¤±è´¥ï¼Œå°è¯•ä»æ•´ç¯‡æ–‡æœ¬æå–")
        try:
            prompt = prompts.get_step1_comprehensive_descriptive_extraction_prompt(report_text)
            response = extractor.call_api(prompt)
            parsed = parse_diagnostic_response(response, "æ•´ç¯‡æè¿°æ€§å†…å®¹æå–")
            if parsed and parsed.get("descriptive_findings"):
                patient_symptoms.append(parsed)
                findings_count = len(parsed.get('descriptive_findings', []))
                excluded_count = len(parsed.get('excluded_content', []))
                print(f"   âœ… æ•´ç¯‡æ–‡æœ¬: æå–{findings_count}ä¸ªæè¿°æ€§å‘ç°ï¼Œæ’é™¤{excluded_count}ä¸ªè¯Šæ–­åˆ¤æ–­")
            else:
                print("   âš ï¸ æ•´ç¯‡æ–‡æœ¬: æœªå‘ç°æœ‰æ•ˆæè¿°æ€§å†…å®¹")
        except Exception as e:
            print_error_info(e, report_num, "æ•´ç¯‡æè¿°æ€§å†…å®¹æå–")
    
    # ç¬¬ä¸‰æ­¥ï¼šä»åŒ»ç”Ÿè¯Šæ–­ä¸­æå–å™¨å®˜
    print_step_info(3, "åŒ»ç”Ÿè¯Šæ–­å™¨å®˜æå–", len(physician_chunks))
    diagnosed_organs = []
    
    for i, chunk in enumerate(physician_chunks):
        print_api_call_info(api_key_name, report_num, "å™¨å®˜æå–", i+1)
        try:
            prompt = prompts.get_step2_diagnosis_organ_extraction_prompt(chunk['content']).replace("{text_content}", chunk['content'])
            response = extractor.call_api(prompt)
            parsed = parse_diagnostic_response(response, f"å™¨å®˜æå–-å—{i+1}")
            if parsed:
                diagnosed_organs.append(parsed)
                print(f"   âœ… å—{i+1}: æˆåŠŸæå–å™¨å®˜")
            else:
                print(f"   âš ï¸ å—{i+1}: å™¨å®˜æå–å¤±è´¥")
        except Exception as e:
            print_error_info(e, report_num, f"å™¨å®˜æå–-å—{i+1}")

    # å›é€€ï¼šè‹¥æœªè¯†åˆ«åˆ°åŒ»ç”Ÿè¯Šæ–­å—æˆ–æœªèƒ½æå–å‡ºå™¨å®˜ï¼Œåˆ™å¯¹æ•´ç¯‡æ–‡æœ¬æ‰§è¡Œä¸€æ¬¡å™¨å®˜æå–
    if not physician_chunks or not diagnosed_organs:
        print("   âš ï¸ æœªè¯†åˆ«åˆ°æœ‰æ•ˆåŒ»ç”Ÿè¯Šæ–­å—æˆ–å™¨å®˜ï¼Œè§¦å‘æ•´ç¯‡å™¨å®˜æå–å›é€€")
        fallback_results = _fallback_extract_organs_on_full_text(extractor, report_text, prompts, report_num, api_key_name)
        diagnosed_organs.extend([res for res in fallback_results if res])
    
    # ç¬¬å››æ­¥ï¼šæ•´åˆç»“æœå¹¶è¿›è¡Œè§£å‰–æ˜ å°„
    print_step_info(4, "ç—‡çŠ¶-å™¨å®˜è§£å‰–æ˜ å°„")
    final_step3_result = None
    if patient_symptoms and diagnosed_organs:
        print_api_call_info(api_key_name, report_num, "è§£å‰–æ˜ å°„")
        try:
            prompt = prompts.get_step3_anatomical_mapping_prompt(
                patient_symptoms, diagnosed_organs, report_text
            )
            response = extractor.call_api(prompt)
            final_step3_result = parse_diagnostic_response(response, "è§£å‰–æ˜ å°„")
            
            if final_step3_result:
                print("   âœ… è§£å‰–æ˜ å°„æˆåŠŸ")
                print_extraction_summary(final_step3_result)
            else:
                print("   âš ï¸ è§£å‰–æ˜ å°„å¤±è´¥")
        except Exception as e:
            print_error_info(e, report_num, "è§£å‰–æ˜ å°„")
    else:
        print("   âš ï¸ ç¼ºå°‘ç—‡çŠ¶æˆ–å™¨å®˜ä¿¡æ¯ï¼Œè·³è¿‡è§£å‰–æ˜ å°„")
    
    # å¦‚æœä¸‰æ­¥æ³•æˆåŠŸï¼Œè¿›è¡Œæ ‡å‡†åŒ–
    if final_step3_result:
        print("   âœ… ä¸‰æ­¥æ³•æå–æˆåŠŸï¼Œè¿›è¡Œæ ‡å‡†åŒ–...")
        try:
            normalized_output = _normalize_outputs(patient_symptoms, diagnosed_organs, final_step3_result, report_text)
            return {"raw": final_step3_result, "normalized": normalized_output}
        except Exception as e:
            print_error_info(e, report_num, "æ ‡å‡†åŒ–è¾“å‡ºæ„å»º")
            # å¦‚æœæ ‡å‡†åŒ–å¤±è´¥ï¼Œå°†ç»§ç»­å°è¯•æ•´åˆæç¤ºè¯

    # å¦‚æœä¸‰æ­¥æ³•å¤±è´¥æˆ–æ ‡å‡†åŒ–å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æ•´åˆæç¤ºè¯ä½œä¸ºæœ€ç»ˆç»“æœ
    print_step_info("å¤‡é€‰", "ä½¿ç”¨æ•´åˆæç¤ºè¯é‡è¯•")
    try:
        print_api_call_info(api_key_name, report_num, "æ•´åˆæç¤ºè¯")
        prompt = prompts.get_integrated_diagnostic_prompt(report_text)
        response = extractor.call_api(prompt)
        # æ•´åˆæç¤ºè¯ç›´æ¥è¿”å›æœ€ç»ˆæ ¼å¼
        integrated_result = parse_diagnostic_response(response, "æ•´åˆæç¤ºè¯")
        
        if integrated_result:
            print("   âœ… æ•´åˆæç¤ºè¯æˆåŠŸ")
            # æ•´åˆæç¤ºè¯çš„ç»“æœå°±æ˜¯æ ‡å‡†åŒ–çš„ç»“æœ
            print_extraction_summary(integrated_result)
            
            # åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„ "raw" ç”¨äºæ—¥å¿—è®°å½•å’Œå…¼å®¹æ€§
            raw_dummy = {
                "source": "integrated_prompt",
                "step1_patient_complaints": patient_symptoms,
                "step2_physician_diagnoses": diagnosed_organs
            }
            # ç¡®ä¿æ•´åˆæç¤ºè¯çš„ç»“æœæ˜¯åˆ—è¡¨æ ¼å¼
            if isinstance(integrated_result, dict):
                # å¦‚æœæ˜¯å•ä¸ªå­—å…¸ï¼ŒåŒ…è£…æˆæ ‡å‡†çš„ s -> U æ ¼å¼ï¼ˆæ¢å¤ä¸ºå ä½ç—‡çŠ¶ï¼‰
                wrapped_result = [{
                    "s_symptom": "integrated_extraction", 
                    "U_unit_set": [{"u_unit": integrated_result}]
                }]
                return {"raw": raw_dummy, "normalized": wrapped_result}
            else:
                return {"raw": raw_dummy, "normalized": integrated_result}
        else:
            print("   âŒ æ•´åˆæç¤ºè¯ä¹Ÿå¤±è´¥")
            # è¿”å›éƒ¨åˆ†æ•°æ®ä»¥ä¾›è°ƒè¯•
            return {
                "raw": {"step1": patient_symptoms, "step2": diagnosed_organs, "step3": None}, 
                "normalized": []
            }
            
    except Exception as e:
        print_error_info(e, report_num, "æ•´åˆæç¤ºè¯")
        return {
            "raw": {"step1": patient_symptoms, "step2": diagnosed_organs, "step3": "error"}, 
            "normalized": []
        }

def main():
    parser = argparse.ArgumentParser(description='Diag_Distillation ä¸‰æ­¥åˆ†ç¦»å¼è¯Šæ–­è’¸é¦ç³»ç»Ÿ')
    parser.add_argument('--input_dir', type=str, required=True, help='è¾“å…¥ç›®å½•è·¯å¾„')
    parser.add_argument('--output_dir', type=str, required=True, help='è¾“å‡ºç›®å½•è·¯å¾„')
    parser.add_argument('--api_key_name', type=str, required=True, help='APIå¯†é’¥åç§°')
    parser.add_argument('--start_index', type=int, required=True, help='å¼€å§‹ç´¢å¼•')
    parser.add_argument('--end_index', type=int, required=True, help='ç»“æŸç´¢å¼•')
    parser.add_argument('--log_level', type=str, default='INFO', help='æ—¥å¿—çº§åˆ«')
    
    args = parser.parse_args()
    
    # æ‰“å°ç³»ç»Ÿå¯åŠ¨ä¿¡æ¯
    print_header()
    
    # æ‰“å°é…ç½®ä¿¡æ¯
    print("âš™ï¸ è¿è¡Œé…ç½®:")
    print(f"   ğŸ“ è¾“å…¥ç›®å½•: {args.input_dir}")
    print(f"   ğŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"   ğŸ”‘ APIå¯†é’¥: {args.api_key_name}")
    print(f"   ğŸ“Š å¤„ç†èŒƒå›´: {args.start_index} - {args.end_index}")
    print(f"   ğŸ“‹ æ—¥å¿—çº§åˆ«: {args.log_level}")
    print("-" * 80)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    os.makedirs(os.path.join(args.output_dir, 'diagnostic_results'), exist_ok=True)
    os.makedirs(os.path.join(args.output_dir, 'logs'), exist_ok=True)
    
    # åˆå§‹åŒ–APIé…ç½®
    if args.api_key_name not in MULTI_API_CONFIG:
        print(f"âŒ APIå¯†é’¥ '{args.api_key_name}' ä¸å­˜åœ¨äºé…ç½®ä¸­")
        sys.exit(1)
    
    api_config = MULTI_API_CONFIG[args.api_key_name]
    print(f"ğŸ”§ APIé…ç½®: {api_config['model']} @ {api_config['base_url']}")
    
    # åˆå§‹åŒ–æå–å™¨å’Œæç¤ºè¯
    extractor = LLMExtractor(
        model=api_config['model'],
        api_key=api_config['api_key'],
        base_url=api_config['base_url']
    )
    prompts = DiagnosticExtractionPrompts()
    
    print("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    print("=" * 80)
    
    # å¼€å§‹å¤„ç†
    start_time = time.time()
    total_files = args.end_index - args.start_index + 1
    processed_count = 0
    success_count = 0
    error_count = 0
    
    for i in range(args.start_index, args.end_index + 1):
        print_progress(processed_count, total_files, start_time)
        
        # å°è¯•txtæ–‡ä»¶ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™å°è¯•jsonæ–‡ä»¶
        txt_file = os.path.join(args.input_dir, f'report_{i}.txt')
        json_file = os.path.join(args.input_dir, f'report_{i}.json')
        output_file = os.path.join(args.output_dir, 'diagnostic_results', f'diagnostic_{i}.json')
        
        input_file = None
        if os.path.exists(txt_file):
            input_file = txt_file
        elif os.path.exists(json_file):
            input_file = json_file
        
        if not input_file:
            print(f"âš ï¸ è·³è¿‡: report_{i} (txtå’Œjsonæ–‡ä»¶éƒ½ä¸å­˜åœ¨)")
            processed_count += 1
            continue
        
        try:
            # è¯»å–è¾“å…¥æ–‡ä»¶
            if input_file.endswith('.txt'):
                with open(input_file, 'r', encoding='utf-8') as f:
                    text_content = f.read()
                report_data = {
                    'text': text_content,
                    'case_id': str(i),
                    'filename': f'report_{i}.txt'
                }
                print(f"ğŸ“„ è¯»å–txtæ–‡ä»¶: {input_file}")
            else:
                with open(input_file, 'r', encoding='utf-8') as f:
                    report_data = json.load(f)
                print(f"ğŸ“„ è¯»å–jsonæ–‡ä»¶: {input_file}")
            
            # å¤„ç†æŠ¥å‘Š
            result = process_report_with_diagnostic_steps(extractor, report_data, i, prompts, args.api_key_name)
            
            if result:
                # ä¿å­˜ç»“æœ
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(result, f, ensure_ascii=False, indent=2)
                print_file_save_info(output_file, True)
                
                # è‹¥åŒ…å«æ ‡å‡†åŒ–ç»“æœï¼Œå¦å­˜ä¸€ä»½æ›´æ˜“ç”¨çš„JSON
                try:
                    normalized_dir = os.path.join(args.output_dir, 'diagnostic_results_normalized')
                    os.makedirs(normalized_dir, exist_ok=True)
                    normalized_file = os.path.join(normalized_dir, f'diagnostic_{i}.json')
                    normalized_payload = result.get('normalized') if isinstance(result, dict) else None
                    if normalized_payload:
                        with open(normalized_file, 'w', encoding='utf-8') as f2:
                            json.dump(normalized_payload, f2, ensure_ascii=False, indent=2)
                        print_file_save_info(normalized_file, True)
                except Exception as e:
                    print_error_info(e, i, "å†™å…¥æ ‡å‡†åŒ–JSON")
                
                success_count += 1
            else:
                print(f"âŒ æŠ¥å‘Š {i}: å¤„ç†å¤±è´¥")
                error_count += 1
            
        except Exception as e:
            print_error_info(e, i)
            print(f"   è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            error_count += 1
        
        processed_count += 1
        print("â”€" * 60)
    
    # æ‰“å°æœ€ç»ˆç»Ÿè®¡
    total_time = time.time() - start_time
    print("=" * 80)
    print("ğŸ‰ å¤„ç†å®Œæˆ!")
    print(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
    print(f"   âœ… æˆåŠŸ: {success_count}")
    print(f"   âŒ å¤±è´¥: {error_count}")
    print(f"   ğŸ“ æ€»è®¡: {processed_count}")
    print(f"   â° æ€»ç”¨æ—¶: {int(total_time//60)}:{int(total_time%60):02d}")
    print(f"   ğŸ“ˆ æˆåŠŸç‡: {(success_count/processed_count*100):.1f}%" if processed_count > 0 else "   ğŸ“ˆ æˆåŠŸç‡: 0%")
    print("=" * 80)

if __name__ == "__main__":
    main() 